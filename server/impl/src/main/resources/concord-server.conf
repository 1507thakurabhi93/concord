concord-server {

    # API port
    port = 8001

    db {
        url = "jdbc:postgresql://localhost:5432/postgres"
        url = ${?DB_URL}

        appUsername = "postgres"
        appUsername = ${?DB_USERNAME}

        # appPassword = "..."
        appPassword= ${?DB_PASSWORD}

        inventoryUsername = "postgres"
        inventoryUsername = ${?DB_INVENTORY_USERNAME}

        # inventoryPassword = "..."
        inventoryPassword = ${?DB_INVENTORY_PASSWORD}

        maxPoolSize = 10
    }

    # email notifications
    email {
        enabled = false

        host = "localhost"
        port = "25"

        connectTimeout = 20000
        readTimeout = 10000

        from = "noreply@example.com"
    }

    process {
        # default process configuration
        defaultConfiguration = null

        # the period between checks for failed or stalled processes (sec)
        # if zero the task is disabled
        watchdogPeriod = 3

        # the state cleanup interval (sec)
        # if zero the task is disabled
        cleanupInterval = 3600

        # enable cleanup of the process queue
        queueCleanup = true

        # enable cleanup of the process state table
        stateCleanup = true

        # enable cleanup of the process events table
        eventsCleanup = true

        # enable cleanup of the process logs
        logsCleanup = true

        # max age of the process state data (ms)
        maxStateAge = 604800000

        # max age of failed processes to handle (PG interval)
        maxFailureHandlingAge = "3 days"

        # max age of stalled processes to handle (PG interval)
        maxStalledAge = "1 minute"

        # max age of processes which are failed to start (PG interval)
        maxStartFailureAge = "10 minutes"

        # list of process state files that must be encrypted before storing
        secureFiles: ["_main.json"]

        # process state archive
        archive {
            # the archival task's period (sec)
            # if zero the task is disabled
            period = 0

            # the period between checking for stalled archive uploads (sec)
            # if zero the task is disabled
            stalledCheckPeriod = 0

            # maximum time after which the entry will be considered "stalled" (ms)
            stalledAge = 3600000

            # maximum process age after which it is moved to the archive (ms)
            processAge = 86400000

            # maximum parallelism of upload operations
            uploadThreads = 4

            # max age of an archive (ms), disabled if 0
            maxArchiveAge = 1209600000
        }

        checkpoints {

            # process checkpoint
            archive {
                # the archival task's period (sec)
                # if zero the task is disabled
                period = 0

                # maximum checkpoint age after which it is moved to the archive (ms)
                checkpointAge = 86400000

                # the period between checks for stalled archive uploads (sec)
                # if zero the task is disabled
                stalledCheckPeriod = 0

                # maximum time after which the entry will be considered "stalled" (ms)
                stalledAge = 3600000

                # maximum parallelism of upload operations
                uploadThreads = 4

                # max age of an archive (ms), disabled if 0
                maxArchiveAge = 1209600000
            }
        }
    }

    queue {
        # maximum rate at which processes are allowed to start (proc/sec)
        # zero or a negative value disables the rate limiting
        rateLimit = 5

        # maximum time to wait if the process start was rate limited (ms)
        maxRateTimeout = 10000
    }

    audit {
        enabled = true

        # the log cleanup interval (sec)
        # if zero the task is disabled
        cleanupPeriod = 3600

        # max age of the audit log data (ms)
        maxLogAge = 604800000
    }

    repositoryCache {
        # directory to store the local repo cache
        # created automatically if not specified
        # cacheDir = "/tmp/concord/repos"

        # directory to store the local repo cache metadata
        # created automatically if not specified
        # metaDir = "/tmp/concord/repo_meta"

        # check if concord.yml is present in the repo
        concordFileValidationEnabled = false

        # timeout for checkout operations (ms)
        lockTimeout = 180000
    }

    template {
        # directory to store process template cache
        # created automatically if not specified
        # cacheDir = "/tmp/concord/templates"
    }

    secretStore {
        default = concord

        # maximum allowed size of binary secrets (bytes)
        maxSecretDataSize = 1048576

        # maximum allowed size of encrypted strings (used in `crypto.decryptString`, bytes)
        maxEncryptedStringLength = 102400

        # default values, change for production (base64)
        # serverPassword = "..."
        # secretStoreSalt = "..."
        # projectSecretSalt = "..."

        concord {
            enabled = true
        }

        keywhiz {
            enabled = false
            url = "https://localhost:4444"
            trustStore = "/path/to/trustStore.p12"
            # trustStorePassword = "..."
            keyStore = "/path/to/keystore.p12"
            # keyStorePassword = "..."
            connectTimeout = 5000
            soTimeout = 5000
            connectionRequestTimeout = 5000
        }
    }

    triggers {
        # disabling all triggers mean that all events (including repository refresh) will be disabled
        disableAll: false

        # the specified event types will be ignored
        disabled: []
    }

    # API key authentication
    apiKey {
        expirationEnabled = false

        # default expiration period (days)
        expirationPeriod =  30

        # how often Concord will send expiration notifications (days)
        notifyBeforeDays = [1, 3, 7, 15]
    }

    # AD/LDAP authentication
    ldap {
        url = "ldap://oldap:389"
        searchBase = "dc=example,dc=org"
        principalSearchFilter = "(cn={0})"
        userSearchFilter = "(cn=*{0}*)"
        usernameProperty = "cn"
        mailProperty = "mail"
        systemUsername = "cn=admin,dc=example,dc=org"
        # systemPassword = "..."
    }

    git {
        # oauth = "..."

        # use GIT's shallow clone
        shallowClone = true

        httpLowSpeedLimit = 1
        httpLowSpeedTime = 600
        sshTimeoutRetryCount = 1
        sshTimeout = 600
    }

    # GitHub integration
    github {
        githubDomain = "github.com"
        githubDomain = ${?GITHUB_DOMAIN}

        # default value, for testing only
        secret = "12345"

        defaultFilter = {
            unknownRepo = false
        }
    }

    s3 {
        # list of S3-compatible endpoints
        destinations: [
            {
                url: "http://localhost:9090",
                url: ${?S3_URL}
                accessKey: "a",
                secretKey: "b",
                bucketName: "archive"
            },
            {
                url: "http://localhost:9091",
                url: ${?S3_URL}
                accessKey: "a",
                secretKey: "b",
                bucketName: "archive"
            }
        ]
    }

    ansibleEvents {
        # how often the ansible event processing should run (sec)
        # if zero the task is disabled
        period = 2

        # how many records to featch at the time
        fetchLimit = 1000
    }

    development {
    }

    production {
    }
}
